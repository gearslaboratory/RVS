{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ee' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#ee.Authenticate()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mee\u001b[49m\u001b[38;5;241m.\u001b[39mInitialize()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeemap\u001b[39;00m\n\u001b[0;32m      4\u001b[0m Map \u001b[38;5;241m=\u001b[39m geemap\u001b[38;5;241m.\u001b[39mMap(center\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m36\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m120\u001b[39m], zoom \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ee' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#ee.Authenticate()\n",
    "ee.Initialize()\n",
    "import geemap\n",
    "Map = geemap.Map(center=[36,-120], zoom =8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make stack of LANDFIRE inputs:\n",
    "    BPS code\n",
    "    BPS name\n",
    "    BPS model\n",
    "    EVH\n",
    "    EVC\n",
    "    Lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Collection: {'type': 'ImageCollection', 'bands': [], 'features': [{'type': 'Image', 'bands': [{'id': 'B0', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [136595, 87376], 'crs': 'GEOGCS[\"WGS 84\", \\n  DATUM[\"World Geodetic System 1984\", \\n    SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], \\n    AUTHORITY[\"EPSG\",\"6326\"]], \\n  PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], \\n  UNIT[\"degree\", 0.017453292519943295], \\n  AXIS[\"Geodetic longitude\", EAST], \\n  AXIS[\"Geodetic latitude\", NORTH], \\n  AUTHORITY[\"EPSG\",\"4326\"]]', 'crs_transform': [0.00026949458523585647, 0, -124.84902599680046, 0, -0.00026949458523585647, 49.38461324988546]}], 'properties': {'system:index': '2_0'}}]}\n"
     ]
    }
   ],
   "source": [
    "#AOI\n",
    "aoi = ee.Geometry.BBox(-121.351882, 36.480156 , -120.861284,36.874108)\n",
    "#Start geemap \n",
    "Map = geemap.Map(center=[36,-120], zoom =8)\n",
    "\n",
    "\n",
    "bps = ee.ImageCollection(\"LANDFIRE/Vegetation/BPS/v1_4_0\").reduce(ee.Reducer.max())\n",
    "#rapcovers = ee.ImageCollection(\"LANDFIRE/Vegetation/EVH/v1_4_0\").reduce(ee.Reducer.max())\n",
    "evh = ee.ImageCollection(\"LANDFIRE/Vegetation/EVH/v1_4_0\").reduce(ee.Reducer.max())\n",
    "rapcoverha = ee.Image(\"projects/rap-data-365417/assets/vegetation-cover-v3/2014\").select('AFG')\n",
    "rapcoverhp = ee.Image(\"projects/rap-data-365417/assets/vegetation-cover-v3/2014\").select('PFG') \n",
    "sclass = ee.ImageCollection(\"LANDFIRE/Fire/SClass/v1_4_0\").reduce(ee.Reducer.max())\n",
    "\n",
    "rapcoverh = rapcoverha.add(rapcoverhp)\n",
    "\n",
    "col = ee.ImageCollection([])\n",
    "for year in range(2022,2023):\n",
    "    # Define the GeoTIFF file path in the GCS bucket\n",
    "    geotiff_path = f'gs://gigafire_rvs/rpms/rpms_{year}.tif' \n",
    "    \n",
    "    # Load the GeoTIFF as an image\n",
    "    image = ee.Image.loadGeoTIFF(geotiff_path)\n",
    "    \n",
    "    # Add the image to the image collection\n",
    "    col = col.merge(ee.ImageCollection([image]))\n",
    "\n",
    "# Print the image collection\n",
    "print(\"Image Collection:\", col.getInfo())\n",
    "\n",
    "\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "\n",
    "\n",
    "rpms_percentiles = col.reduce(ee.Reducer.percentile(percentiles))\n",
    "\n",
    "col = ee.ImageCollection(\"LANDSAT/LC08/C01/T1_32DAY_NDVI\")\n",
    "\n",
    "def annual_composite(year):\n",
    "    start_date = ee.Date.fromYMD(year, 1, 1)\n",
    "    end_date = ee.Date.fromYMD(year, 12, 31)\n",
    "    annual_ndvi = col.filterDate(start_date, end_date).median().set('year', year)\n",
    "    return annual_ndvi\n",
    "    \n",
    "    # Create annual composites for each year in the range\n",
    "start_year = 2013\n",
    "end_year = 2021\n",
    "annual_ndvi_collection = ee.ImageCollection.fromImages(\n",
    "    [annual_composite(year) for year in range(start_year, end_year + 1)])\n",
    "\n",
    "# Compute percentiles\n",
    "ndvi_percentiles = annual_ndvi_collection.reduce(ee.Reducer.percentile(percentiles))\n",
    "\n",
    "#Gridmet precip\n",
    "gridmet = ee.ImageCollection(\"IDAHO_EPSCOR/GRIDMET\").select(['pr'])\n",
    "\n",
    "#Gridmet annual sums\n",
    "def annual_composite(year):\n",
    "    start_date = ee.Date.fromYMD(year, 1, 1)\n",
    "    end_date = ee.Date.fromYMD(year, 12, 31)\n",
    "    annual_precip = gridmet.filterDate(start_date, end_date).sum().set('year', year)\n",
    "    return annual_precip\n",
    "    \n",
    "    # Create annual composites for each year in the range\n",
    "start_year = 1979\n",
    "end_year = 2023\n",
    "annual_precip_collection = ee.ImageCollection.fromImages(\n",
    "    [annual_composite(year) for year in range(start_year, end_year + 1)])\n",
    "\n",
    "precip_percentiles = annual_precip_collection.reduce(ee.Reducer.percentile(percentiles))\n",
    "\n",
    "\n",
    "landfire_stack = ee.Image(\n",
    "        [bps, rapcoverh, evh,ndvi_percentiles, precip_percentiles, sclass,rpms_percentiles]).toFloat()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "bucket_id = \"gigafire_rvs\"\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(bucket_id)\n",
    "# list all objects in the directory\n",
    "blobs = bucket.list_blobs(prefix=\"lf\")\n",
    "for blob in blobs:\n",
    "    blob.delete()\n",
    "\n",
    "#Export tiles to bucket (shard size 256)\n",
    "def export_stack_to_cloud_storage(stack):\n",
    "    # ee_region_bbox = ee_region.bounds()\n",
    "    # print(ee_region_bbox.coordinates())\n",
    "    task = ee.batch.Export.image.toCloudStorage(\n",
    "        image=stack,\n",
    "        fileNamePrefix=\"lf\",\n",
    "        bucket=bucket_id,\n",
    "        scale=30,\n",
    "        crs='EPSG:4326',\n",
    "        shardSize=256,\n",
    "        region=aoi,\n",
    "        fileDimensions=256,\n",
    "        skipEmptyTiles=True,\n",
    "        maxPixels=1e13,\n",
    "        fileFormat=\"GeoTIFF\",\n",
    "        formatOptions={\n",
    "            'cloudOptimized': True\n",
    "        }\n",
    "    )\n",
    "    task.start()\n",
    "\n",
    "export_stack_to_cloud_storage(landfire_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ingli\\AppData\\Local\\Temp\\tmp68e2cpyr\n",
      "Downloaded files: ['C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000000-0000000000.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000000-0000000256.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000000-0000000512.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000000-0000000768.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000000-0000001024.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000000-0000001280.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000000-0000001536.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000000-0000001792.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000256-0000000000.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000256-0000000256.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000256-0000000512.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000256-0000000768.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000256-0000001024.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000256-0000001280.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000256-0000001536.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000256-0000001792.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000512-0000000000.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000512-0000000256.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000512-0000000512.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000512-0000000768.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000512-0000001024.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000512-0000001280.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000512-0000001536.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000512-0000001792.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000768-0000000000.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000768-0000000256.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000768-0000000512.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000768-0000000768.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000768-0000001024.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000768-0000001280.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000768-0000001536.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000000768-0000001792.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001024-0000000000.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001024-0000000256.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001024-0000000512.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001024-0000000768.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001024-0000001024.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001024-0000001280.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001024-0000001536.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001024-0000001792.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001280-0000000000.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001280-0000000256.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001280-0000000512.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001280-0000000768.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001280-0000001024.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001280-0000001280.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001280-0000001536.tif', 'C:\\\\Users\\\\ingli\\\\AppData\\\\Local\\\\Temp\\\\tmp68e2cpyr\\\\lf0000001280-0000001792.tif']\n"
     ]
    }
   ],
   "source": [
    "###Download from bucket to tmp folder\n",
    "\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "bucket_id = \"gigafire_rvs\"\n",
    "#wd = \"C:/Users/ingli/OneDrive - University of Nevada, Reno/Desktop/unr/git/RVS/240226_test/temp\"\n",
    "# Create a temporary directory to download the files\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(temp_dir)\n",
    "\n",
    "def list_files_in_bucket(bucket_name):\n",
    "    \"\"\"List all files in a Google Cloud Storage bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    files = []\n",
    "    blobs = bucket.list_blobs(prefix=\"lf\")\n",
    "    for blob in blobs:\n",
    "        files.append(blob.name)\n",
    "\n",
    "    return files\n",
    "\n",
    "def download_files_from_bucket(bucket_name, local_temp_dir):\n",
    "    \"\"\"Download files from a Google Cloud Storage bucket to a local directory.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    local_files = []\n",
    "    blobs = bucket.list_blobs(prefix=\"lf\")\n",
    "    for blob in blobs:\n",
    "        local_file_path = os.path.join(local_temp_dir, blob.name)\n",
    "        blob.download_to_filename(local_file_path)\n",
    "        local_files.append(local_file_path)\n",
    "\n",
    "    return local_files\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Download files to temporary directory\n",
    "local_files = download_files_from_bucket(bucket_id, temp_dir)\n",
    "print(\"Downloaded files:\", local_files)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            x          y  BPS_max   AFG  EVH_max      NDVI_p5     NDVI_p25  \\\n",
      "0 -121.282939  36.874001    950.0  67.0    104.0  1816.177612  2155.356445   \n",
      "1 -121.282669  36.874001    950.0  56.0    104.0  2516.092773  2751.035156   \n",
      "2 -121.282400  36.874001    950.0  44.0    107.0  2516.092773  2751.035156   \n",
      "3 -121.282130  36.874001    950.0  44.0    104.0  3471.396484  3791.721191   \n",
      "4 -121.281861  36.874001    950.0  58.0    104.0  2678.726807  3007.115723   \n",
      "\n",
      "      NDVI_p50     NDVI_p75     NDVI_p95  ...      pr_p25      pr_p50  \\\n",
      "0  2365.049316  2841.971436  3011.120605  ...  323.512482  407.297546   \n",
      "1  3005.544434  3017.038818  3365.416504  ...  323.512482  407.297546   \n",
      "2  3005.544434  3017.038818  3365.416504  ...  323.512482  407.297546   \n",
      "3  3886.108398  4047.327637  4687.019531  ...  323.512482  407.297546   \n",
      "4  3151.767334  3272.114990  4484.061035  ...  323.512482  407.297546   \n",
      "\n",
      "       pr_p75      pr_p95  SClass_max   B0_p5  B0_p25  B0_p50  B0_p75  B0_p95  \n",
      "0  495.700012  727.970581         2.0  4079.0  4079.0  4079.0  4079.0  4079.0  \n",
      "1  495.700012  727.970581         2.0  4415.0  4415.0  4415.0  4415.0  4415.0  \n",
      "2  495.700012  727.970581         2.0  4415.0  4415.0  4415.0  4415.0  4415.0  \n",
      "3  495.700012  727.970581         2.0  5470.0  5470.0  5470.0  5470.0  5470.0  \n",
      "4  495.700012  727.970581         2.0     NaN     NaN     NaN     NaN     NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "##Geotiff to dataframe\n",
    "\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multiband_geotiff_to_dataframe(geotiff_path):\n",
    "    \"\"\"Converts a multiband GeoTIFF file into a pandas DataFrame with x and y coordinates.\"\"\"\n",
    "    # Open the GeoTIFF file\n",
    "    with rasterio.open(geotiff_path) as src:\n",
    "        # Read all bands\n",
    "        num_bands = src.count\n",
    "        band_data = [src.read(i) for i in range(1, num_bands + 1)]\n",
    "        \n",
    "        # Get metadata\n",
    "        transform = src.transform\n",
    "        height, width = band_data[0].shape\n",
    "\n",
    "        # Generate x and y coordinates\n",
    "        x_coords = []\n",
    "        y_coords = []\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                x, y = src.xy(i, j)\n",
    "                x_coords.append(x)\n",
    "                y_coords.append(y)\n",
    "\n",
    "        # Flatten band data and coordinates into DataFrame\n",
    "        df_data = {'x': x_coords, 'y': y_coords}\n",
    "        for band_idx in range(num_bands):\n",
    "            band_name = src.descriptions[band_idx] if src.descriptions else f'band_{band_idx + 1}'\n",
    "            df_data[band_name] = band_data[band_idx].flatten()\n",
    "\n",
    "        df = pd.DataFrame(df_data)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "dfs = [multiband_geotiff_to_dataframe(file_path) for file_path in local_files]\n",
    "\n",
    "for df in dfs:\n",
    "    # Identify NDVI columns\n",
    "    ndvi_columns = [col for col in df.columns if col.startswith('NDVI_')]\n",
    "    \n",
    "    # Apply the power operation to NDVI columns\n",
    "    if ndvi_columns:  # Check if there are any NDVI columns\n",
    "        df[ndvi_columns] = df[ndvi_columns].apply(lambda x: x * 10000)\n",
    "\n",
    "print(dfs[1].head())\n",
    "\n",
    "# Clean up temporary directory\n",
    "for file_path in local_files:\n",
    "    os.remove(file_path)\n",
    "os.rmdir(temp_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "##Join df to kattribute table and reorder and clean columns\n",
    "key = pd.read_csv(\"C:/Users/ingli/OneDrive - University of Nevada, Reno/Desktop/unr/git/RVS/240226_test/LF_140BPS_01122015.csv\")\n",
    "height_key = pd.read_csv(\"C:/Users/ingli/OneDrive - University of Nevada, Reno/Desktop/unr/git/RVS/240226_test/LF_140EVH_05092014.csv\")\n",
    "\n",
    "def join_new_attributes(df):  \n",
    "    join = df.join(key[['VALUE','BPS_CODE', 'BPS_NAME','BPS_MODEL']].set_index('VALUE'), on='BPS_max')\n",
    "    join = join.join(height_key[['VALUE','height']].set_index('VALUE'), on='EVH_max', how=\"outer\")\n",
    "    join = join.assign(PLOT_ID=range(len(join)))\n",
    "    cols = list(join.columns)\n",
    "    Plots_Active = join[['PLOT_ID', 'BPS_CODE', 'BPS_NAME', 'BPS_MODEL', \n",
    "                     'AFG', 'height',\n",
    "                     'y', 'x', *cols[10:15], *cols[5:10], 'SClass_max', *cols[16:21]]]\n",
    "    return Plots_Active\n",
    "\n",
    "\n",
    "dfs = [join_new_attributes(df) for df in dfs]\n",
    "print(len(dfs))\n",
    "\n",
    "#for i, df in enumerate(dfs):\n",
    "    #df.to_csv(f'rvs_inputdf_{i}.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template DB copied successfully.# Path to the SQLite database file\n",
      "C:/Users/ingli/Desktop/home/240529_landfire_plots_cover_1.db\n",
      "['PLOT_ID', 'BPS_CODE', 'BPS_NAME', 'BPS_MODEL', 'herb_cover', 'herb_height', 'latitude', 'longitude', 'PPT_1', 'PPT_2', 'PPT_3', 'PPT_4', 'PPT_5', 'NDVI_1', 'NDVI_2', 'NDVI_3', 'NDVI_4', 'NDVI_5', 'sclass', 'NPP_1', 'NPP_2', 'NPP_3', 'NPP_4', 'NPP_5']\n",
      "Final DB copied successfully to inputs\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:/Users/ingli/Desktop/home/240529_landfire_plots_cover_2.db'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m destination_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/ingli/Desktop/home/240529_landfire_plots_cover_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.db\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(destination_file):\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m shutil\u001b[38;5;241m.\u001b[39mcopy(source_file, destination_file)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTemplate DB copied successfully.# Path to the SQLite database file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:/Users/ingli/Desktop/home/240529_landfire_plots_cover_2.db'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Copy template to home folder for reading and writing \n",
    "source_file = 'C:/Users/ingli/OneDrive - University of Nevada, Reno/Desktop/unr/git/RVS/test/rvs_demo_fromRobbAddFieldTypeMissing.db'\n",
    "counter=0\n",
    "\n",
    "for i in dfs:\n",
    "    counter=counter+1\n",
    "    destination_file = f'C:/Users/ingli/Desktop/home/240529_landfire_plots_cover_{counter}.db'\n",
    "\n",
    "    if os.path.exists(destination_file):\n",
    "        os.remove(destination_file)\n",
    "\n",
    "    shutil.copy(source_file, destination_file)\n",
    "    print(\"Template DB copied successfully.# Path to the SQLite database file\")\n",
    "    database_path = destination_file\n",
    "    print(database_path)\n",
    "\n",
    "# Create a connection to the database\n",
    "    conn = sqlite3.connect(database_path)\n",
    "\n",
    "# Define the table name\n",
    "    table_name = \"Plots_Active\"\n",
    "\n",
    "# Get the column names of the table\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    cols= [column[1] for column in cursor.fetchall()]  + ['NPP_1', 'NPP_2', 'NPP_3', 'NPP_4', 'NPP_5']\n",
    "    print(cols)\n",
    "    # Read data from pandas DataFrame\n",
    "    # Assuming df is your pandas DataFrame with the same column names\n",
    "\n",
    "\n",
    "    i.columns=cols\n",
    "    # Replace values in the table with pandas DataFrame values\n",
    "    i.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns_info = cursor.fetchall()\n",
    "    npp_columns = [column[1] for column in columns_info if column[1].startswith(\"NPP\")]\n",
    "\n",
    "    # Execute UPDATE statements to set NULL values to 0 for each NPP column\n",
    "    for column_name in npp_columns:\n",
    "        update_query = f\"UPDATE {table_name} SET {column_name} = 0 WHERE {column_name} IS NULL\"\n",
    "        cursor.execute(update_query)\n",
    "\n",
    "    table_name=\"Shrubs_Active\"\n",
    "    cursor.execute(f\"DELETE FROM {table_name}\")\n",
    "\n",
    "    table_name=\"Disturbance_Plots_NoFire\"\n",
    "    cursor.execute(f\"DROP TABLE {table_name}\")\n",
    "\n",
    "    table_name=\"Dist_year7fire\"\n",
    "    cursor.execute(f\"DROP TABLE {table_name}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Get the list of column names that start with \"NPP\"\n",
    "   \n",
    "\n",
    "    #conn.execute(f\"UPDATE Plots_Active SET sclass = 10\") \n",
    "\n",
    "    # Commit changes and close connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "#Copy file from home to RVS git folder for RVS use\n",
    "    source_file = f'C:/Users/ingli/Desktop/home/240529_landfire_plots_cover_{counter}.db'\n",
    "    destination_file = f'C:/Users/ingli/OneDrive - University of Nevada, Reno/Desktop/unr/git/RVS/240226_test/inputs/240529_landfire_plots_cover_{counter}.db'\n",
    "    shutil.copy(source_file, destination_file)\n",
    "    print(\"Final DB copied successfully to inputs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2663764\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "docker run -v \"C:/Users/ingli/OneDrive - University of Nevada, Reno/Desktop/unr/git/RVS/240226_test\":\"/data\" rvs-image-2024 rvs /data/240404_landfire_plots_rpms_200.db /data/out.db 100\n",
      "0.0\n",
      "  Rows  Execution Time (seconds)\n",
      "0  200                       0.0\n"
     ]
    }
   ],
   "source": [
    "rows = [200]\n",
    "\n",
    "# DataFrame to store execution times\n",
    "execution_times_df = pd.DataFrame(columns=['Rows', 'Execution Time (seconds)'])\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "print(len(combined_df))\n",
    "# Number of iterations\n",
    "\n",
    "# DataFrame to store execution times\n",
    "execution_times_df = pd.DataFrame(columns=['Rows', 'Execution Time (seconds)'])\n",
    "\n",
    "for i in rows:\n",
    "    \n",
    "    source_file = 'C:/Users/ingli/Desktop/home/240404_landfire_plots_rpms.db'\n",
    "    destination_file = f'C:/Users/ingli/Desktop/home/240404_landfire_plots_rpms_{i}.db'\n",
    "    shutil.copy(source_file, destination_file)\n",
    "    print(\"File copied successfully.\")\n",
    "\n",
    "    conn = sqlite3.connect(destination_file)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "\n",
    "    cursor.execute(f'''\n",
    "    DELETE FROM Plots_Active\n",
    "    WHERE PLOT_ID NOT IN (\n",
    "        SELECT PLOT_ID FROM Plots_Active\n",
    "        ORDER BY PLOT_ID ASC\n",
    "        LIMIT {i}\n",
    "    )\n",
    "    ''')\n",
    "        \n",
    "    conn.commit()\n",
    "    conn.execute('VACUUM')\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "    source_file = f'C:/Users/ingli/Desktop/home/240404_landfire_plots_rpms_{i}.db'\n",
    "    destination_file = f'C:/Users/ingli/OneDrive - University of Nevada, Reno/Desktop/unr/git/RVS/240226_test/240404_landfire_plots_rpms_{i}.db'\n",
    "    shutil.copy(source_file, destination_file)\n",
    "    print(\"File copied successfully.\")\n",
    "\n",
    "    source_file = f'/data/240404_landfire_plots_rpms_{i}.db'\n",
    "\n",
    "# Command with the file path containing 'i'\n",
    "    command = f\"docker run -v \\\"C:/Users/ingli/OneDrive - University of Nevada, Reno/Desktop/unr/git/RVS/240226_test\\\":\\\"/data\\\" rvs-image-2024 rvs {source_file} /data/out.db 100\"\n",
    "    print(command)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Execute the command\n",
    "    #!{command}\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    \n",
    "    print(execution_time)\n",
    "    # Append execution time to DataFrame\n",
    "    execution_times_df = pd.concat([execution_times_df, pd.DataFrame([{'Rows': i, 'Execution Time (seconds)': execution_time}])], ignore_index=True)\n",
    "\n",
    "print(execution_times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution_times_df)\n",
    "#execution_times_df.set_index('Rows', inplace=True)\n",
    "#execution_times_df.reset_index(inplace=True)\n",
    "execution_times_df['Rows'] = pd.to_numeric(execution_times_df['Rows'])\n",
    "execution_times_df.plot(x='Rows', y='Execution Time (seconds)', kind='line', title='RVS execution time vs. db size', xlabel='No. of rows', ylabel='Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!docker run -v \"C:/Users/ingli/OneDrive - University of Nevada, Reno/Desktop/unr/git/RVS/240226_test\":\"/data\" rvs-image-2024-dev rvs /data/inputs/240529_landfire_plots_cover_1.db /data/outs/out.db 10 false"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
